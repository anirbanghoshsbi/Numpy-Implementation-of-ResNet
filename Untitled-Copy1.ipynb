{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.Conv2d(3,1,5,bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight=a.weight.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 5, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.random.randn(1,3,10,10)\n",
    "#print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t = torch.Tensor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1=a(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 6, 6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.6439,  0.1042,  0.9349, -0.2174,  1.1587,  0.5587],\n",
      "          [-0.8270,  0.6404, -0.3992,  0.0206,  0.6010,  0.2179],\n",
      "          [ 0.3176,  0.7107, -1.1323,  0.8479,  0.4106,  0.5089],\n",
      "          [ 0.4725,  1.4909,  0.1159,  0.1552, -0.0220,  0.4360],\n",
      "          [ 0.6602,  0.5010, -0.3170,  0.2713, -0.2759,  0.1182],\n",
      "          [ 0.1458, -0.5018,  0.6976, -0.9957, -1.0071,  0.4233]]]])\n"
     ]
    }
   ],
   "source": [
    "print(out1.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"conv.npy\",weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = nn.Conv2d(3,1,5,bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.weight.data = torch.from_numpy(np.load(\"conv.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.6439,  0.1042,  0.9349, -0.2174,  1.1587,  0.5587],\n",
       "          [-0.8270,  0.6404, -0.3992,  0.0206,  0.6010,  0.2179],\n",
       "          [ 0.3176,  0.7107, -1.1323,  0.8479,  0.4106,  0.5089],\n",
       "          [ 0.4725,  1.4909,  0.1159,  0.1552, -0.0220,  0.4360],\n",
       "          [ 0.6602,  0.5010, -0.3170,  0.2713, -0.2759,  0.1182],\n",
       "          [ 0.1458, -0.5018,  0.6976, -0.9957, -1.0071,  0.4233]]]],\n",
       "       grad_fn=<ThnnConv2DBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from components import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = conv_layer(1,3,5,5,relu=False,shift=False,same=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.kernel = np.load(\"conv.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.64390754,  0.10424934,  0.93487625, -0.21735137,\n",
       "           1.15870506,  0.55874438],\n",
       "         [-0.82695555,  0.64036988, -0.39921057,  0.02062556,\n",
       "           0.60100873,  0.21787797],\n",
       "         [ 0.31758256,  0.71066057, -1.13227425,  0.84794921,\n",
       "           0.41055384,  0.50888551],\n",
       "         [ 0.47251187,  1.49089464,  0.11593225,  0.15517025,\n",
       "          -0.02198019,  0.43598352],\n",
       "         [ 0.66016086,  0.50096008, -0.31697324,  0.27126971,\n",
       "          -0.27592393,  0.11823851],\n",
       "         [ 0.14575134, -0.50175454,  0.6976147 , -0.99572854,\n",
       "          -1.00707023,  0.42325358]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.forward(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inchannel=3\n",
    "outchannel=5\n",
    "stride=1\n",
    "a=nn.Sequential(\n",
    "                nn.Conv2d(inchannel,outchannel,3,stride, 1,bias=False),\n",
    "                nn.BatchNorm2d(outchannel),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(outchannel,outchannel,3,1,1,bias=False),\n",
    "                nn.BatchNorm2d(outchannel) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-1.41490549e-01,  1.24487430e-02, -1.27088994e-01],\n",
       "         [-1.65476024e-01,  1.80382565e-01,  4.44823653e-02],\n",
       "         [-1.74373180e-01, -4.63182479e-02, -4.59060222e-02]],\n",
       "\n",
       "        [[-1.78726673e-01,  4.20582145e-02,  3.80870998e-02],\n",
       "         [ 1.77206352e-01,  1.01934358e-01,  1.32908896e-01],\n",
       "         [ 2.94911861e-02, -5.09202778e-02, -9.50937569e-02]],\n",
       "\n",
       "        [[-1.03681140e-01,  4.83361632e-02,  2.53126323e-02],\n",
       "         [ 1.18817911e-01,  3.84557098e-02, -4.26621139e-02],\n",
       "         [-9.91018638e-02,  4.60903347e-02,  1.07585236e-01]]],\n",
       "\n",
       "\n",
       "       [[[-5.25829196e-02,  1.38322711e-02,  1.68484047e-01],\n",
       "         [-1.38810143e-01,  5.10664284e-03,  7.49129802e-02],\n",
       "         [ 1.40049919e-01, -1.81042150e-01,  8.19766521e-03]],\n",
       "\n",
       "        [[-4.16046530e-02,  1.88611701e-01,  1.62825719e-01],\n",
       "         [-1.56836778e-01,  9.17243958e-03, -9.39253792e-02],\n",
       "         [ 4.96571958e-02, -1.15324080e-01,  4.25802320e-02]],\n",
       "\n",
       "        [[-4.34169769e-02,  1.75759196e-04,  1.12145841e-02],\n",
       "         [ 7.92357773e-02,  7.37691373e-02,  8.43387693e-02],\n",
       "         [ 1.91540375e-01, -6.16327226e-02,  1.59203112e-02]]],\n",
       "\n",
       "\n",
       "       [[[-1.78454280e-01, -3.53376865e-02, -1.37167096e-01],\n",
       "         [-6.84530810e-02, -1.24088570e-01,  7.82770365e-02],\n",
       "         [-1.86643213e-01,  8.12539905e-02, -1.16812594e-01]],\n",
       "\n",
       "        [[-1.51081279e-01, -1.65865496e-01,  1.70104459e-01],\n",
       "         [ 1.24508902e-01,  1.40694007e-01, -1.55939609e-02],\n",
       "         [ 1.16739765e-01, -2.23366916e-03,  1.12418637e-01]],\n",
       "\n",
       "        [[-1.54749691e-01, -1.09324835e-01,  1.08824953e-01],\n",
       "         [-6.61025941e-03,  1.34296194e-01, -4.30188179e-02],\n",
       "         [-1.64607689e-01, -6.60132617e-02, -1.08883180e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 5.83754331e-02,  1.44067392e-01, -1.00801483e-01],\n",
       "         [-4.53730375e-02,  8.50242376e-03,  1.56846195e-02],\n",
       "         [-1.17198661e-01,  1.80693850e-01,  1.63464829e-01]],\n",
       "\n",
       "        [[ 1.63139686e-01, -1.66553408e-01,  1.37902498e-02],\n",
       "         [ 1.55116037e-01, -1.71855941e-01, -1.32322758e-02],\n",
       "         [ 2.58308649e-03,  5.71347475e-02,  2.78511643e-03]],\n",
       "\n",
       "        [[-1.46876097e-01,  3.39531600e-02,  3.12999934e-02],\n",
       "         [ 1.56090364e-01, -1.49452612e-01, -1.18152142e-01],\n",
       "         [-8.30279365e-02,  7.76800066e-02,  1.27045706e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 1.35863766e-01,  1.55655250e-01,  1.37253746e-01],\n",
       "         [ 8.07816833e-02,  1.54290244e-01, -5.58678210e-02],\n",
       "         [ 4.35816199e-02, -1.15616225e-01,  4.30075228e-02]],\n",
       "\n",
       "        [[ 1.14483073e-01, -1.67152360e-01, -1.82789564e-03],\n",
       "         [-1.41803414e-01, -4.91645932e-03, -9.23768058e-02],\n",
       "         [ 9.00242180e-02, -1.13652766e-01,  8.62933844e-02]],\n",
       "\n",
       "        [[-1.61136687e-03, -7.43570924e-03, -5.10713160e-02],\n",
       "         [ 1.42719433e-01,  6.39702827e-02, -5.36397099e-04],\n",
       "         [-1.82779595e-01, -4.63331342e-02, -2.15457082e-02]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].weight.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<generator object Module.parameters at 0x7fa52f05f888>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<generator object Module.parameters at 0x7fa52f05f888>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<generator object Module.parameters at 0x7fa52f05f888>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<generator object Module.parameters at 0x7fa52f05f570>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<generator object Module.parameters at 0x7fa52f05f570>\n"
     ]
    }
   ],
   "source": [
    "for l in a:\n",
    "    print(type(l))\n",
    "    try:\n",
    "        print(l.parameters())\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from components import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(network, self).__init__()\n",
    "        self.layer = nn.Sequential(nn.BatchNorm2d(num_classes))\n",
    "    def forward(self,x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = bn_layer(3,0.1,False)\n",
    "bn2 = network(3)\n",
    "bn2.layer[0].weight.data = torch.from_numpy(bn.gamma).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_n = np.random.randn(1,3,4,4)\n",
    "img2_n = np.random.randn(1,3,4,4)\n",
    "img1_t = torch.from_numpy(img1_n).float()\n",
    "img2_t = torch.from_numpy(img2_n).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.48585924, -0.45232367, -0.94919701, -0.37046044],\n",
       "         [ 0.07904035, -0.71310832,  0.5969297 , -0.30896816],\n",
       "         [ 0.34148571, -0.0798479 , -0.57836106, -0.36461039],\n",
       "         [-0.37794595, -0.08334672, -0.40784686, -0.48754231]],\n",
       "\n",
       "        [[-0.2892108 ,  0.11154834, -0.66249014,  0.61013076],\n",
       "         [-0.24198313, -0.39830278, -0.01164733,  0.46522103],\n",
       "         [-0.6212576 , -0.35391929,  0.30996768,  0.48931926],\n",
       "         [-1.20650098, -0.92723088, -0.65510758, -0.79230333]],\n",
       "\n",
       "        [[ 0.2489486 , -0.57351983, -0.14663972, -0.28788796],\n",
       "         [-0.79312912,  0.70729198,  0.01946437, -0.09615678],\n",
       "         [-0.10428968, -0.04661531, -0.28864947, -0.09086866],\n",
       "         [ 1.1353075 ,  0.46643466, -0.17470275, -0.26670681]]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.forward(img1_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.4859, -0.4523, -0.9492, -0.3705],\n",
       "          [ 0.0790, -0.7131,  0.5969, -0.3090],\n",
       "          [ 0.3415, -0.0798, -0.5784, -0.3646],\n",
       "          [-0.3779, -0.0833, -0.4078, -0.4875]],\n",
       "\n",
       "         [[-0.2892,  0.1115, -0.6625,  0.6101],\n",
       "          [-0.2420, -0.3983, -0.0116,  0.4652],\n",
       "          [-0.6213, -0.3539,  0.3100,  0.4893],\n",
       "          [-1.2065, -0.9272, -0.6551, -0.7923]],\n",
       "\n",
       "         [[ 0.2489, -0.5735, -0.1466, -0.2879],\n",
       "          [-0.7931,  0.7073,  0.0195, -0.0962],\n",
       "          [-0.1043, -0.0466, -0.2886, -0.0909],\n",
       "          [ 1.1353,  0.4664, -0.1747, -0.2667]]]],\n",
       "       grad_fn=<ThnnBatchNormBackward>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn2.eval()\n",
    "bn2(img1_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0167,  0.0314, -0.0092])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn2.running_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "from components import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_n = np.random.randn(1,3,4,4)\n",
    "img_t = torch.from_numpy(img_n).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33159395 0.52190435 0.61738452 0.21191126 0.50618843 0.8064209\n",
      "  0.70805529 0.91552036 0.21372474 0.13540403]]\n",
      "[[0.33159395 0.52190435 0.61738452 0.21191126 0.50618843 0.8064209\n",
      "  0.70805529 0.91552036 0.21372474 0.13540403]]\n"
     ]
    }
   ],
   "source": [
    "fc1 = fc_sigmoid(48,10)\n",
    "in_n = np.random.randn(1,3,4,4)\n",
    "print(fc1.forward(in_n))\n",
    "fc1.save(\"model2\")\n",
    "fc1.load(\"model2\")\n",
    "print(fc1.forward(in_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyzustc/applications/anaconda3/envs/pytorch4/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.3316, 0.5219, 0.6174, 0.2119, 0.5062, 0.8064, 0.7081, 0.9155, 0.2137,\n",
       "         0.1354]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_t = torch.from_numpy(in_n).float()\n",
    "fc2 = nn.Linear(48,10)\n",
    "fc2.weight.data = torch.from_numpy(fc1.kernel).float()\n",
    "fc2.bias.data = torch.from_numpy(fc1.bias).float()\n",
    "F.sigmoid(fc2(in_t.view(1,-1)))\n",
    "#fc2.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.93398661 -0.96120682]\n",
      "   [ 0.84982901 -0.45364615]]\n",
      "\n",
      "  [[-0.35390512  1.21758953]\n",
      "   [-1.06216017 -0.20850398]]\n",
      "\n",
      "  [[ 0.73691322 -0.07784667]\n",
      "   [-0.51282803 -1.80743656]]]]\n",
      "[[[[-0.93398661 -0.96120682]\n",
      "   [ 0.84982901 -0.45364615]]\n",
      "\n",
      "  [[-0.35390512  1.21758953]\n",
      "   [-1.06216017 -0.20850398]]\n",
      "\n",
      "  [[ 0.73691322 -0.07784667]\n",
      "   [-0.51282803 -1.80743656]]]]\n"
     ]
    }
   ],
   "source": [
    "conv1 = conv_layer(3,3,3,3,stride=2,shift=False)\n",
    "print(conv1.forward(img_n))\n",
    "conv1.save(\"model2\",0)\n",
    "conv1.load(\"model2\",0)\n",
    "print(conv1.forward(img_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True]]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2 = conv_layer(3,3,3,3,shift=False)\n",
    "conv2.save(\"model2\",1)\n",
    "conv1.load(\"model2\",1)\n",
    "conv1.forward(img_n) == conv2.forward(img_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.9340, -0.9612],\n",
       "          [ 0.8498, -0.4536]],\n",
       "\n",
       "         [[-0.3539,  1.2176],\n",
       "          [-1.0622, -0.2085]],\n",
       "\n",
       "         [[ 0.7369, -0.0778],\n",
       "          [-0.5128, -1.8074]]]], grad_fn=<ThnnConv2DBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.load(\"model2\",0)\n",
    "conv3=nn.Conv2d(3,3,3,2,1,bias=False)\n",
    "conv3.weight.data = torch.from_numpy(conv1.kernel).float()\n",
    "conv3(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.37032298 -0.21117014  0.66269664 -0.62966354]\n",
      "   [ 0.02910882 -0.58174473  0.20295718  1.01033166]\n",
      "   [-0.67549908  0.74279407  0.00227486  0.94608233]\n",
      "   [-1.09908411 -0.22880733 -0.60555583  0.06495622]]\n",
      "\n",
      "  [[-0.47921464  0.29390613 -0.24745017  0.19032162]\n",
      "   [-0.46129668 -1.44116053  0.01464917  0.07320266]\n",
      "   [ 0.63052077 -2.01672901 -0.45748305  1.4064442 ]\n",
      "   [ 0.66742259  1.17064474 -0.26580088  0.92202308]]\n",
      "\n",
      "  [[ 0.04026574 -0.44212289  0.93698062 -0.18723935]\n",
      "   [-0.51301174  0.18925162  0.51255169 -0.0096111 ]\n",
      "   [-0.09181671 -0.63527102  0.64541279  0.87498831]\n",
      "   [-0.8138256   0.58604354 -0.68609195 -0.40650396]]]]\n",
      "[[[[ 0.37032298 -0.21117014  0.66269664 -0.62966354]\n",
      "   [ 0.02910882 -0.58174473  0.20295718  1.01033166]\n",
      "   [-0.67549908  0.74279407  0.00227486  0.94608233]\n",
      "   [-1.09908411 -0.22880733 -0.60555583  0.06495622]]\n",
      "\n",
      "  [[-0.47921464  0.29390613 -0.24745017  0.19032162]\n",
      "   [-0.46129668 -1.44116053  0.01464917  0.07320266]\n",
      "   [ 0.63052077 -2.01672901 -0.45748305  1.4064442 ]\n",
      "   [ 0.66742259  1.17064474 -0.26580088  0.92202308]]\n",
      "\n",
      "  [[ 0.04026574 -0.44212289  0.93698062 -0.18723935]\n",
      "   [-0.51301174  0.18925162  0.51255169 -0.0096111 ]\n",
      "   [-0.09181671 -0.63527102  0.64541279  0.87498831]\n",
      "   [-0.8138256   0.58604354 -0.68609195 -0.40650396]]]]\n"
     ]
    }
   ],
   "source": [
    "bn1 = bn_layer(3,0.1)\n",
    "print(bn1.forward(img_n))\n",
    "bn1.save(\"model2\",0)\n",
    "bn2=bn_layer(3,0.1)\n",
    "bn2.load(\"model2\",0)\n",
    "print(bn2.forward(img_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.3703, -0.2112,  0.6627, -0.6297],\n",
       "          [ 0.0291, -0.5817,  0.2030,  1.0103],\n",
       "          [-0.6755,  0.7428,  0.0023,  0.9461],\n",
       "          [-1.0991, -0.2288, -0.6056,  0.0650]],\n",
       "\n",
       "         [[-0.4792,  0.2939, -0.2475,  0.1903],\n",
       "          [-0.4613, -1.4412,  0.0146,  0.0732],\n",
       "          [ 0.6305, -2.0167, -0.4575,  1.4064],\n",
       "          [ 0.6674,  1.1706, -0.2658,  0.9220]],\n",
       "\n",
       "         [[ 0.0403, -0.4421,  0.9370, -0.1872],\n",
       "          [-0.5130,  0.1893,  0.5126, -0.0096],\n",
       "          [-0.0918, -0.6353,  0.6454,  0.8750],\n",
       "          [-0.8138,  0.5860, -0.6861, -0.4065]]]],\n",
       "       grad_fn=<ThnnBatchNormBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn3 = nn.BatchNorm2d(3)\n",
    "bn3.weight.data = torch.from_numpy(bn1.gamma).float()\n",
    "bn3.bias.data = torch.from_numpy(bn1.bias).float()\n",
    "bn3(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from components import *\n",
    "from network import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool1 = nn.MaxPool2d(3,2,1)\n",
    "pool2 = max_pooling(3,3,2,same=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_n = np.random.randn(1,3,4,4)\n",
    "img_t = torch.from_numpy(img_n).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.8111, 0.8111],\n",
       "          [2.0129, 0.8111]],\n",
       "\n",
       "         [[1.4927, 1.4927],\n",
       "          [0.9597, 0.5876]],\n",
       "\n",
       "         [[0.7131, 1.8063],\n",
       "          [0.6432, 1.8063]]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool1(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.81109292, 0.81109292],\n",
       "         [2.01288087, 0.81109292]],\n",
       "\n",
       "        [[1.49269599, 1.49269599],\n",
       "         [0.95968562, 0.58759207]],\n",
       "\n",
       "        [[0.7131152 , 1.80625993],\n",
       "         [0.64321338, 1.80625993]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2.forward(img_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortcut1 = nn.Sequential(\n",
    "    nn.Conv2d(3,3,1,2,bias=False),\n",
    "    nn.BatchNorm2d(3)\n",
    ")\n",
    "shortcut2 = [\n",
    "    conv_layer(3,3,1,1,stride=2,shift=False),\n",
    "    bn_layer(3)\n",
    "]\n",
    "res1 = ResidualBlock(3,3,shortcut=shortcut1,stride=2)\n",
    "res2 = ResBlock(3,3,shortcut=shortcut2,stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_n = np.random.randn(1,3,64,64)\n",
    "img_t = torch.from_numpy(img_n).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.1956, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 1.0576, 0.0000,  ..., 0.0000, 0.0000, 0.0110],\n",
      "          [0.0000, 0.7581, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0328, 0.0000,  ..., 0.0000, 0.0000, 0.3593],\n",
      "          [0.4085, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5659, 1.3135, 0.5124,  ..., 0.1804, 1.9723, 1.0949]],\n",
      "\n",
      "         [[0.0000, 0.2908, 0.1065,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [2.2875, 1.6648, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.4575,  ..., 0.3034, 0.0120, 0.0000],\n",
      "          [1.2890, 1.9937, 0.7339,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0910, 0.0452, 0.1072,  ..., 0.0600, 0.0886, 0.0521],\n",
      "          [0.0192, 0.0421, 0.0561,  ..., 0.0244, 0.0935, 0.0259],\n",
      "          [0.0819, 0.0873, 0.0000,  ..., 0.0299, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.2844,  ..., 0.0000, 0.0508, 0.0381],\n",
      "          [0.1211, 0.0000, 0.0108,  ..., 0.0000, 0.0381, 0.0481],\n",
      "          [0.0000, 0.0283, 0.0000,  ..., 0.0000, 0.0000, 0.0481]]]],\n",
      "       grad_fn=<ReluBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1=res1(img_t)\n",
    "print(out1)\n",
    "res1.save(\"model2\",0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.1955766  0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         1.05759938 0.         ... 0.         0.\n",
      "    0.01102751]\n",
      "   [0.         0.75810055 0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.         0.03276589 0.         ... 0.         0.\n",
      "    0.35933995]\n",
      "   [0.40849523 0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.56589417 1.31352564 0.5123667  ... 0.18039478 1.97228508\n",
      "    1.09489038]]\n",
      "\n",
      "  [[0.         0.29083432 0.10651162 ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [2.28753476 1.66475367 0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.45752486 ... 0.30337522 0.01203619\n",
      "    0.        ]\n",
      "   [1.28903192 1.99368505 0.73388472 ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]]\n",
      "\n",
      "  [[0.0910214  0.04517135 0.10718874 ... 0.06000121 0.08859605\n",
      "    0.05207598]\n",
      "   [0.01919392 0.04210623 0.05612959 ... 0.0243898  0.09346632\n",
      "    0.02590547]\n",
      "   [0.08194996 0.08731176 0.         ... 0.02992258 0.\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.28440504 ... 0.         0.0507838\n",
      "    0.0380912 ]\n",
      "   [0.12106192 0.         0.01077238 ... 0.         0.03814416\n",
      "    0.04809765]\n",
      "   [0.         0.02830848 0.         ... 0.         0.\n",
      "    0.04808855]]]]\n"
     ]
    }
   ],
   "source": [
    "res2.load(\"model2\",0,0)\n",
    "out2 = res2.forward(img_n)\n",
    "print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.        , 0.        , 0.63739676, 1.69083682],\n",
       "         [0.        , 1.46089696, 0.        , 0.28717502],\n",
       "         [0.09282276, 0.        , 0.        , 0.28314992],\n",
       "         [1.04631531, 0.        , 0.        , 0.68330254]],\n",
       "\n",
       "        [[1.51723686, 1.94290681, 0.10202827, 1.74922489],\n",
       "         [0.        , 0.95225736, 0.        , 0.        ],\n",
       "         [1.15688942, 0.        , 0.31625065, 0.        ],\n",
       "         [0.053589  , 0.        , 1.0236157 , 0.        ]],\n",
       "\n",
       "        [[1.38060865, 0.        , 0.70403283, 1.50128155],\n",
       "         [1.88076878, 0.79142563, 0.        , 0.1000511 ],\n",
       "         [0.        , 0.26272548, 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.84432434, 0.        ]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3 = ResBlock(3,3)\n",
    "res3.load(\"model2\",0,0)\n",
    "res3.forward(img_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from components import *\n",
    "from model import *\n",
    "from network import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet1 = ResNet(10)\n",
    "resnet2 = resnet34(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_n = np.random.randn(2,3,64,64)\n",
    "img_t = torch.from_numpy(img_n).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet1.train()\n",
    "resnet2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3847, 0.5873, 0.4455, 0.5531, 0.3581, 0.5054, 0.6434, 0.5189, 0.4082,\n",
      "         0.4635],\n",
      "        [0.4045, 0.5968, 0.3785, 0.6000, 0.4178, 0.4848, 0.6369, 0.5392, 0.4968,\n",
      "         0.3964]], grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyzustc/applications/anaconda3/envs/pytorch4/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "out1 = resnet1(img_t)\n",
    "print(out1)\n",
    "resnet1.save(\"model3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.38466223 0.58728573 0.44550358 0.55313538 0.35814501 0.5054044\n",
      "  0.64339455 0.51894347 0.40819916 0.46345911]\n",
      " [0.40454431 0.59680723 0.37845852 0.59996407 0.41780575 0.48479948\n",
      "  0.63694661 0.53924949 0.4967846  0.39641447]]\n"
     ]
    }
   ],
   "source": [
    "resnet2.load(\"model3\")\n",
    "out2 = resnet2.forward(img_n)\n",
    "print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet34(20)\n",
    "resnet.load(\"model\")\n",
    "resnet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.622"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(resnet, \"test.txt\", 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.09801900e-04 8.44545644e-05 1.50593346e-05 3.57817904e-04\n",
      "  3.08214764e-04 2.21263866e-04 7.96619784e-06 4.70830549e-06\n",
      "  2.93430969e-03 6.72559968e-03 7.27888947e-04 2.26620316e-05\n",
      "  3.56806322e-04 1.35024008e-03 1.48415206e-03 1.10775207e-03\n",
      "  4.25204683e-03 2.08454651e-03 5.55587686e-03 1.47450242e-05]\n",
      " [3.95397406e-04 1.89027682e-03 5.87159106e-03 1.17129888e-03\n",
      "  2.21837458e-03 1.42912302e-02 3.62404498e-03 5.94532539e-03\n",
      "  2.37927778e-03 1.33571168e-04 3.37912909e-03 2.30805128e-02\n",
      "  1.51540933e-03 8.04028333e-05 5.58865640e-04 1.89172760e-04\n",
      "  1.06103357e-04 2.41654175e-03 5.98565302e-06 1.29179726e-03]]\n",
      "[[1.94043394e-03 2.47524660e-03 4.80953481e-03 5.91570887e-04\n",
      "  2.95932687e-04 6.25699848e-03 6.42321159e-05 1.45352046e-03\n",
      "  1.69235191e-02 4.72698295e-02 5.62685151e-03 2.52583094e-02\n",
      "  1.12183035e-01 9.87436345e-02 2.27230358e-02 1.21836351e-01\n",
      "  2.82764870e-02 1.86596170e-01 2.54497525e-03 2.01029293e-04]\n",
      " [4.03041690e-03 1.73233618e-03 4.59881191e-01 1.72592290e-03\n",
      "  3.64178733e-04 6.86805319e-03 9.12018951e-05 5.32287320e-03\n",
      "  7.74689637e-03 4.13379294e-04 2.67737095e-03 4.85348248e-02\n",
      "  4.21330592e-02 1.94769707e-02 3.50409673e-02 5.11275295e-02\n",
      "  2.48849630e-02 1.27832182e-01 5.80858880e-04 2.55704138e-04]]\n"
     ]
    }
   ],
   "source": [
    "resnet.train()\n",
    "print(resnet.forward(img_n))\n",
    "resnet.eval()\n",
    "print(resnet.forward(img_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from components import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.65201156 -0.65276455  0.42748015  1.14846052]\n",
      "   [ 0.5613146  -0.70843531  1.35480667  1.46334856]\n",
      "   [-1.4805167   0.05096754 -0.48446579  0.427778  ]\n",
      "   [ 0.35781664  0.02776046 -0.6047517  -0.18278761]]\n",
      "\n",
      "  [[ 1.18400268  1.25704435 -0.89922669  0.26221404]\n",
      "   [ 0.67342427  0.37302791  0.26892079 -0.39476291]\n",
      "   [ 0.73569614  0.43660496 -1.62787813 -0.06380098]\n",
      "   [-0.36603845 -0.17920875 -0.78149196 -0.19902797]]\n",
      "\n",
      "  [[-0.6933167   0.49699675 -0.49657437  0.19270786]\n",
      "   [ 0.1435731   1.00104979  0.43584249 -1.53290703]\n",
      "   [ 1.74258157  0.43007764  0.76135623 -0.60185224]\n",
      "   [-0.84122451  0.78020748  0.61943179  0.88532944]]]\n",
      "\n",
      "\n",
      " [[[ 0.64363537 -0.66098193 -0.86903735 -0.37759287]\n",
      "   [ 1.50856902  0.11032407 -2.53452893  0.68953566]\n",
      "   [ 0.35658182 -0.36205733  1.91549833  0.7708291 ]\n",
      "   [ 0.31711567  1.43885893  1.02401815 -0.40577161]]\n",
      "\n",
      "  [[-2.05985692 -0.7746743  -1.08655822 -0.70243247]\n",
      "   [-0.49991868 -0.39888537 -0.70492336 -1.16948859]\n",
      "   [ 1.03390643 -0.41150341  0.3174521   1.21964452]\n",
      "   [ 1.37773854 -1.36773313  0.71827959 -0.19552507]]\n",
      "\n",
      "  [[-0.14687592  0.09898403  0.6840228   0.69317657]\n",
      "   [-0.60386052  0.96098515  0.01693995  0.51653814]\n",
      "   [ 0.15862207  0.21933617  0.48826464  0.08706253]\n",
      "   [-0.69151224 -1.25573889 -0.96753107 -0.67180236]]]]\n"
     ]
    }
   ],
   "source": [
    "img_n = np.random.randn(2,3,4,4)\n",
    "print(img_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.5613146  1.46334856]\n",
      "   [0.5613146  1.46334856]]\n",
      "\n",
      "  [[1.25704435 1.25704435]\n",
      "   [0.73569614 0.43660496]]\n",
      "\n",
      "  [[1.00104979 1.00104979]\n",
      "   [1.74258157 1.00104979]]]\n",
      "\n",
      "\n",
      " [[[1.50856902 0.68953566]\n",
      "   [1.50856902 1.91549833]]\n",
      "\n",
      "  [[0.         0.        ]\n",
      "   [1.37773854 1.21964452]]\n",
      "\n",
      "  [[0.96098515 0.96098515]\n",
      "   [0.96098515 0.96098515]]]]\n"
     ]
    }
   ],
   "source": [
    "pool = max_pooling(3,3,2,same=True)\n",
    "print(pool.forward(img_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0. 0. 0. 0.]\n",
      "   [2. 0. 0. 2.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 2. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [1. 1. 0. 0.]\n",
      "   [0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 3. 0. 0.]\n",
      "   [1. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 0.]\n",
      "   [2. 0. 0. 1.]\n",
      "   [0. 0. 1. 0.]\n",
      "   [0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [1. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 4. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "pool.backward(np.ones([2,3,2,2]))\n",
    "print(pool.in_diff_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0]] [[1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "index = pool.maxindex\n",
    "h_index=(index[:,:,0,0]/2).astype(np.int32)\n",
    "w_index=index[:,:,0,0]-2*h_index\n",
    "print(h_index,w_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0. 0. 0. 0.]\n",
      "   [0. 1. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 1. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 1. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "b=np.zeros([1,3,4,4])\n",
    "b[0,range(3),h_index,w_index]+=1\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from components import *\n",
    "from network import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_n = np.random.randn(1,3,64,64)\n",
    "in_t = torch.from_numpy(in_n).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1=resnet34(20)\n",
    "net2=ResNet(20)\n",
    "net2.load(\"model\")\n",
    "net1.load(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.20719721e-06 2.64606663e-06 1.23655365e-06 3.47679628e-07\n",
      "  1.16067845e-06 8.81344457e-06 2.18135805e-06 2.27321728e-06\n",
      "  3.95889043e-06 4.00079370e-06 8.56037501e-07 6.71977745e-07\n",
      "  4.42565487e-07 1.01461827e-06 7.14961725e-07 1.38885709e-06\n",
      "  4.35720316e-07 2.59114813e-07 1.08976252e-06 8.63441828e-07]]\n",
      "tensor([[1.2072e-06, 2.6461e-06, 1.2366e-06, 3.4768e-07, 1.1607e-06, 8.8134e-06,\n",
      "         2.1814e-06, 2.2732e-06, 3.9589e-06, 4.0008e-06, 8.5604e-07, 6.7198e-07,\n",
      "         4.4257e-07, 1.0146e-06, 7.1496e-07, 1.3889e-06, 4.3572e-07, 2.5911e-07,\n",
      "         1.0898e-06, 8.6344e-07]], grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyzustc/applications/anaconda3/envs/pytorch4/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "print(net1.forward(in_n))\n",
    "print(net2(in_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.88178420e-16  4.44089210e-16 -2.22044605e-16]\n",
      "[16. 16. 16.]\n",
      "[[[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      "  [[-6.9388939e-18 -6.9388939e-18 -6.9388939e-18  0.0000000e+00]\n",
      "   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  6.9388939e-18]\n",
      "   [ 6.9388939e-18  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  0.0000000e+00  6.9388939e-18  0.0000000e+00]]\n",
      "\n",
      "  [[ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]]]]\n"
     ]
    }
   ],
   "source": [
    "out1 = fc1.forward(in_n)\n",
    "fc1.backward(np.ones(list(out1.shape)),1)\n",
    "print(record_k-fc1.gamma)\n",
    "print(record_b-fc1.bias)\n",
    "print(fc1.in_diff_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.1592527   1.10576119 -0.3581633  -0.206714  ]\n",
      "   [ 0.94840682  0.36846056 -0.28942049  0.16777784]\n",
      "   [-0.2946678  -0.89425604  0.60020769  0.44965468]\n",
      "   [-1.88560979 -0.15069572  0.55148952  0.04702154]]\n",
      "\n",
      "  [[ 0.08770895  0.09041205  0.06257845 -0.03744275]\n",
      "   [ 0.0573724   0.00628356 -0.02103863 -0.09321322]\n",
      "   [-0.07562964  0.01167789  0.0579549   0.01160989]\n",
      "   [-0.04848374 -0.01818962 -0.09749633  0.00589583]]\n",
      "\n",
      "  [[ 0.69993555 -0.91915484  0.83514142 -1.69100203]\n",
      "   [ 0.43864153 -0.49368064  1.1398632  -0.69938518]\n",
      "   [ 1.46538789  0.24947581 -0.23802811  0.47034674]\n",
      "   [-0.811073    0.87514194 -1.40219926  0.08058899]]]]\n"
     ]
    }
   ],
   "source": [
    "print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=fc2(in_t)\n",
    "s=torch.sum(l)\n",
    "s.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.8164e-08,  1.7169e-07, -2.1854e-07])\n",
      "tensor([16., 16., 16.])\n",
      "tensor([[[[-2.6491e-10,  1.8394e-09, -5.9579e-10, -3.4386e-10],\n",
      "          [ 1.5776e-09,  6.1292e-10, -4.8144e-10,  2.7909e-10],\n",
      "          [-4.9017e-10, -1.4876e-09,  9.9843e-10,  7.4799e-10],\n",
      "          [-3.1367e-09, -2.5068e-10,  9.1739e-10,  7.8219e-11]],\n",
      "\n",
      "         [[-9.0363e-10, -9.3148e-10, -6.4472e-10,  3.8576e-10],\n",
      "          [-5.9109e-10, -6.4737e-11,  2.1675e-10,  9.6034e-10],\n",
      "          [ 7.7918e-10, -1.2031e-10, -5.9709e-10, -1.1961e-10],\n",
      "          [ 4.9951e-10,  1.8740e-10,  1.0045e-09, -6.0743e-11]],\n",
      "\n",
      "         [[ 1.0015e-08, -1.3152e-08,  1.1950e-08, -2.4197e-08],\n",
      "          [ 6.2765e-09, -7.0641e-09,  1.6310e-08, -1.0007e-08],\n",
      "          [ 2.0968e-08,  3.5697e-09, -3.4059e-09,  6.7302e-09],\n",
      "          [-1.1606e-08,  1.2522e-08, -2.0064e-08,  1.1531e-09]]]])\n"
     ]
    }
   ],
   "source": [
    "print(fc2.weight.grad)\n",
    "print(fc2.bias.grad)\n",
    "print(in_t.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.2150], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(fc2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1 2]\n",
      "   [3 4]]]]\n"
     ]
    }
   ],
   "source": [
    "in_n = np.array([[[[1,2],[3,4]]]])\n",
    "print(in_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.0596, -0.3532],\n",
      "          [ 0.3532,  1.0596]]]], grad_fn=<ThnnBatchNormBackward>)\n"
     ]
    }
   ],
   "source": [
    "in_tensor = torch.from_numpy(in_n).float()\n",
    "in_tensor.requires_grad_(True)\n",
    "bn = nn.BatchNorm2d(1)\n",
    "l=bn(in_tensor)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = l[0,0,0,0]+2*l[0,0,0,1]+3*l[0,0,1,0]+4*l[0,0,1,1]\n",
    "s.backward()\n",
    "bn.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.4721])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.weight.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch4]",
   "language": "python",
   "name": "conda-env-pytorch4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
