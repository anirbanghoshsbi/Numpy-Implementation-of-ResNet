{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.Conv2d(3,1,5,bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight=a.weight.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 5, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.random.randn(1,3,10,10)\n",
    "#print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t = torch.Tensor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1=a(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 6, 6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.6439,  0.1042,  0.9349, -0.2174,  1.1587,  0.5587],\n",
      "          [-0.8270,  0.6404, -0.3992,  0.0206,  0.6010,  0.2179],\n",
      "          [ 0.3176,  0.7107, -1.1323,  0.8479,  0.4106,  0.5089],\n",
      "          [ 0.4725,  1.4909,  0.1159,  0.1552, -0.0220,  0.4360],\n",
      "          [ 0.6602,  0.5010, -0.3170,  0.2713, -0.2759,  0.1182],\n",
      "          [ 0.1458, -0.5018,  0.6976, -0.9957, -1.0071,  0.4233]]]])\n"
     ]
    }
   ],
   "source": [
    "print(out1.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"conv.npy\",weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = nn.Conv2d(3,1,5,bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.weight.data = torch.from_numpy(np.load(\"conv.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.6439,  0.1042,  0.9349, -0.2174,  1.1587,  0.5587],\n",
       "          [-0.8270,  0.6404, -0.3992,  0.0206,  0.6010,  0.2179],\n",
       "          [ 0.3176,  0.7107, -1.1323,  0.8479,  0.4106,  0.5089],\n",
       "          [ 0.4725,  1.4909,  0.1159,  0.1552, -0.0220,  0.4360],\n",
       "          [ 0.6602,  0.5010, -0.3170,  0.2713, -0.2759,  0.1182],\n",
       "          [ 0.1458, -0.5018,  0.6976, -0.9957, -1.0071,  0.4233]]]],\n",
       "       grad_fn=<ThnnConv2DBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from components import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = conv_layer(1,3,5,5,relu=False,shift=False,same=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.kernel = np.load(\"conv.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.64390754,  0.10424934,  0.93487625, -0.21735137,\n",
       "           1.15870506,  0.55874438],\n",
       "         [-0.82695555,  0.64036988, -0.39921057,  0.02062556,\n",
       "           0.60100873,  0.21787797],\n",
       "         [ 0.31758256,  0.71066057, -1.13227425,  0.84794921,\n",
       "           0.41055384,  0.50888551],\n",
       "         [ 0.47251187,  1.49089464,  0.11593225,  0.15517025,\n",
       "          -0.02198019,  0.43598352],\n",
       "         [ 0.66016086,  0.50096008, -0.31697324,  0.27126971,\n",
       "          -0.27592393,  0.11823851],\n",
       "         [ 0.14575134, -0.50175454,  0.6976147 , -0.99572854,\n",
       "          -1.00707023,  0.42325358]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.forward(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inchannel=3\n",
    "outchannel=5\n",
    "stride=1\n",
    "a=nn.Sequential(\n",
    "                nn.Conv2d(inchannel,outchannel,3,stride, 1,bias=False),\n",
    "                nn.BatchNorm2d(outchannel),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(outchannel,outchannel,3,1,1,bias=False),\n",
    "                nn.BatchNorm2d(outchannel) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-1.41490549e-01,  1.24487430e-02, -1.27088994e-01],\n",
       "         [-1.65476024e-01,  1.80382565e-01,  4.44823653e-02],\n",
       "         [-1.74373180e-01, -4.63182479e-02, -4.59060222e-02]],\n",
       "\n",
       "        [[-1.78726673e-01,  4.20582145e-02,  3.80870998e-02],\n",
       "         [ 1.77206352e-01,  1.01934358e-01,  1.32908896e-01],\n",
       "         [ 2.94911861e-02, -5.09202778e-02, -9.50937569e-02]],\n",
       "\n",
       "        [[-1.03681140e-01,  4.83361632e-02,  2.53126323e-02],\n",
       "         [ 1.18817911e-01,  3.84557098e-02, -4.26621139e-02],\n",
       "         [-9.91018638e-02,  4.60903347e-02,  1.07585236e-01]]],\n",
       "\n",
       "\n",
       "       [[[-5.25829196e-02,  1.38322711e-02,  1.68484047e-01],\n",
       "         [-1.38810143e-01,  5.10664284e-03,  7.49129802e-02],\n",
       "         [ 1.40049919e-01, -1.81042150e-01,  8.19766521e-03]],\n",
       "\n",
       "        [[-4.16046530e-02,  1.88611701e-01,  1.62825719e-01],\n",
       "         [-1.56836778e-01,  9.17243958e-03, -9.39253792e-02],\n",
       "         [ 4.96571958e-02, -1.15324080e-01,  4.25802320e-02]],\n",
       "\n",
       "        [[-4.34169769e-02,  1.75759196e-04,  1.12145841e-02],\n",
       "         [ 7.92357773e-02,  7.37691373e-02,  8.43387693e-02],\n",
       "         [ 1.91540375e-01, -6.16327226e-02,  1.59203112e-02]]],\n",
       "\n",
       "\n",
       "       [[[-1.78454280e-01, -3.53376865e-02, -1.37167096e-01],\n",
       "         [-6.84530810e-02, -1.24088570e-01,  7.82770365e-02],\n",
       "         [-1.86643213e-01,  8.12539905e-02, -1.16812594e-01]],\n",
       "\n",
       "        [[-1.51081279e-01, -1.65865496e-01,  1.70104459e-01],\n",
       "         [ 1.24508902e-01,  1.40694007e-01, -1.55939609e-02],\n",
       "         [ 1.16739765e-01, -2.23366916e-03,  1.12418637e-01]],\n",
       "\n",
       "        [[-1.54749691e-01, -1.09324835e-01,  1.08824953e-01],\n",
       "         [-6.61025941e-03,  1.34296194e-01, -4.30188179e-02],\n",
       "         [-1.64607689e-01, -6.60132617e-02, -1.08883180e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 5.83754331e-02,  1.44067392e-01, -1.00801483e-01],\n",
       "         [-4.53730375e-02,  8.50242376e-03,  1.56846195e-02],\n",
       "         [-1.17198661e-01,  1.80693850e-01,  1.63464829e-01]],\n",
       "\n",
       "        [[ 1.63139686e-01, -1.66553408e-01,  1.37902498e-02],\n",
       "         [ 1.55116037e-01, -1.71855941e-01, -1.32322758e-02],\n",
       "         [ 2.58308649e-03,  5.71347475e-02,  2.78511643e-03]],\n",
       "\n",
       "        [[-1.46876097e-01,  3.39531600e-02,  3.12999934e-02],\n",
       "         [ 1.56090364e-01, -1.49452612e-01, -1.18152142e-01],\n",
       "         [-8.30279365e-02,  7.76800066e-02,  1.27045706e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 1.35863766e-01,  1.55655250e-01,  1.37253746e-01],\n",
       "         [ 8.07816833e-02,  1.54290244e-01, -5.58678210e-02],\n",
       "         [ 4.35816199e-02, -1.15616225e-01,  4.30075228e-02]],\n",
       "\n",
       "        [[ 1.14483073e-01, -1.67152360e-01, -1.82789564e-03],\n",
       "         [-1.41803414e-01, -4.91645932e-03, -9.23768058e-02],\n",
       "         [ 9.00242180e-02, -1.13652766e-01,  8.62933844e-02]],\n",
       "\n",
       "        [[-1.61136687e-03, -7.43570924e-03, -5.10713160e-02],\n",
       "         [ 1.42719433e-01,  6.39702827e-02, -5.36397099e-04],\n",
       "         [-1.82779595e-01, -4.63331342e-02, -2.15457082e-02]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].weight.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<generator object Module.parameters at 0x7fa52f05f888>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<generator object Module.parameters at 0x7fa52f05f888>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<generator object Module.parameters at 0x7fa52f05f888>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<generator object Module.parameters at 0x7fa52f05f570>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<generator object Module.parameters at 0x7fa52f05f570>\n"
     ]
    }
   ],
   "source": [
    "for l in a:\n",
    "    print(type(l))\n",
    "    try:\n",
    "        print(l.parameters())\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from components import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(network, self).__init__()\n",
    "        self.layer = nn.Sequential(nn.BatchNorm2d(num_classes))\n",
    "    def forward(self,x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = bn_layer(3,0.1,False)\n",
    "bn2 = network(3)\n",
    "bn2.layer[0].weight.data = torch.from_numpy(bn.gamma).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_n = np.random.randn(1,3,4,4)\n",
    "img2_n = np.random.randn(1,3,4,4)\n",
    "img1_t = torch.from_numpy(img1_n).float()\n",
    "img2_t = torch.from_numpy(img2_n).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.48585924, -0.45232367, -0.94919701, -0.37046044],\n",
       "         [ 0.07904035, -0.71310832,  0.5969297 , -0.30896816],\n",
       "         [ 0.34148571, -0.0798479 , -0.57836106, -0.36461039],\n",
       "         [-0.37794595, -0.08334672, -0.40784686, -0.48754231]],\n",
       "\n",
       "        [[-0.2892108 ,  0.11154834, -0.66249014,  0.61013076],\n",
       "         [-0.24198313, -0.39830278, -0.01164733,  0.46522103],\n",
       "         [-0.6212576 , -0.35391929,  0.30996768,  0.48931926],\n",
       "         [-1.20650098, -0.92723088, -0.65510758, -0.79230333]],\n",
       "\n",
       "        [[ 0.2489486 , -0.57351983, -0.14663972, -0.28788796],\n",
       "         [-0.79312912,  0.70729198,  0.01946437, -0.09615678],\n",
       "         [-0.10428968, -0.04661531, -0.28864947, -0.09086866],\n",
       "         [ 1.1353075 ,  0.46643466, -0.17470275, -0.26670681]]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.forward(img1_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.4859, -0.4523, -0.9492, -0.3705],\n",
       "          [ 0.0790, -0.7131,  0.5969, -0.3090],\n",
       "          [ 0.3415, -0.0798, -0.5784, -0.3646],\n",
       "          [-0.3779, -0.0833, -0.4078, -0.4875]],\n",
       "\n",
       "         [[-0.2892,  0.1115, -0.6625,  0.6101],\n",
       "          [-0.2420, -0.3983, -0.0116,  0.4652],\n",
       "          [-0.6213, -0.3539,  0.3100,  0.4893],\n",
       "          [-1.2065, -0.9272, -0.6551, -0.7923]],\n",
       "\n",
       "         [[ 0.2489, -0.5735, -0.1466, -0.2879],\n",
       "          [-0.7931,  0.7073,  0.0195, -0.0962],\n",
       "          [-0.1043, -0.0466, -0.2886, -0.0909],\n",
       "          [ 1.1353,  0.4664, -0.1747, -0.2667]]]],\n",
       "       grad_fn=<ThnnBatchNormBackward>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn2.eval()\n",
    "bn2(img1_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0167,  0.0314, -0.0092])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn2.running_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch4]",
   "language": "python",
   "name": "conda-env-pytorch4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
