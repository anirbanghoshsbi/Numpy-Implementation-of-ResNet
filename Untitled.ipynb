{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer:\n",
    "    def __init__(self, in_channels, out_channels, kernel_h, kernel_w):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_h = kernel_h\n",
    "        self.kernel_w = kernel_w\n",
    "        self.kernel = np.zeros([out_channels, in_channels, kernel_h, kernel_w])\n",
    "        self.bias = np.zeros([out_channels, 1])\n",
    "    def forward(self):\n",
    "        None\n",
    "    def backward(self):\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_layer(layer):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_h, kernel_w, same = True):\n",
    "        layer.__init__(self, in_channels, out_channels, kernel_h, kernel_w)\n",
    "        self.init_param()\n",
    "        self.same = same\n",
    "        \n",
    "    def init_param(self):\n",
    "        self.kernel += 1\n",
    "        self.bias += 1\n",
    "    \n",
    "    @staticmethod\n",
    "    def pad(in_tensor, pad_h, pad_w):\n",
    "        batch_num = in_tensor.shape[0]\n",
    "        in_channels = in_tensor.shape[1]\n",
    "        in_h = in_tensor.shape[2]\n",
    "        in_w = in_tensor.shape[3]\n",
    "        padded = np.zeros([batch_num, in_channels, in_h + 2*pad_h, in_w + 2*pad_w])\n",
    "        padded[:, :, pad_h:pad_h+in_h, pad_w:pad_w+in_w] = in_tensor\n",
    "        return padded\n",
    "    \n",
    "    @staticmethod\n",
    "    def convolution(in_tensor, kernel):\n",
    "        batch_num = in_tensor.shape[0]\n",
    "        in_channels = in_tensor.shape[1]\n",
    "        in_h = in_tensor.shape[2]\n",
    "        in_w = in_tensor.shape[3]\n",
    "        out_channels = kernel.shape[0]\n",
    "        assert kernel.shape[1] == in_channels\n",
    "        kernel_h = kernel.shape[2]\n",
    "        kernel_w = kernel.shape[3]\n",
    "        \n",
    "        out_h = in_h - kernel_h + 1\n",
    "        out_w = in_w - kernel_w + 1\n",
    "        \n",
    "        kernel = kernel.reshape(out_channels, -1)\n",
    "        \n",
    "        extend_in = np.zeros([in_channels*kernel_h*kernel_w, batch_num*out_h*out_w])\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                part_in = in_tensor[:, :, i:i+kernel_h, j:j+kernel_w].reshape(batch_num, -1)\n",
    "                extend_in[:, (i*out_w+j)*batch_num:(i*out_w+j+1)*batch_num] = part_in.T\n",
    "        \n",
    "        out_tensor = np.dot(kernel, extend_in)\n",
    "        out_tensor = out_tensor.reshape(out_channels, out_h*out_w, batch_num)\n",
    "        out_tensor = out_tensor.transpose(2,0,1).reshape(batch_num, out_channels, out_h, out_w) \n",
    "        \n",
    "        return out_tensor\n",
    "    \n",
    "    def forward(self, in_tensor):\n",
    "        if self.same:\n",
    "            in_tensor = conv_layer.pad(in_tensor, int((self.kernel_h-1)/2), int((self.kernel_w-1)/2))\n",
    "        \n",
    "        self.in_tensor = in_tensor\n",
    "        \n",
    "        self.out_tensor = conv_layer.convolution(in_tensor, self.kernel)\n",
    "        self.out_tensor += self.bias.reshape(1,self.out_channels,1,1)\n",
    "        \n",
    "        return self.out_tensor\n",
    "    \n",
    "    def backward(self, out_diff_tensor, lr):\n",
    "        assert out_diff_tensor.shape == self.out_tensor.shape\n",
    "        \n",
    "        bias_diff = np.sum(out_diff_tensor, axis = (0,2,3)).reshape(self.bias.shape)\n",
    "        \n",
    "        kernel_diff = conv_layer.convolution(self.in_tensor.transpose(1,0,2,3), out_diff_tensor.transpose(1,0,2,3))\n",
    "        kernel_diff = kernel_diff.transpose(1,0,2,3)\n",
    "        \n",
    "        padded = conv_layer.pad(out_diff_tensor, self.kernel_h-1, self.kernel_w-1)\n",
    "        kernel_trans = self.kernel.reshape(self.out_channels, self.in_channels, self.kernel_h*self.kernel_w)\n",
    "        kernel_trans = kernel_trans[:,:,::-1].reshape(self.kernel.shape)\n",
    "        self.in_diff_tensor = conv_layer.convolution(padded, kernel_trans.transpose(1,0,2,3))\n",
    "        if self.same:\n",
    "            pad_h = int((self.kernel_h-1)/2)\n",
    "            pad_w = int((self.kernel_w-1)/2)\n",
    "            self.in_diff_tensor = self.in_diff_tensor[:, :, pad_h:-pad_h, pad_w:-pad_w]\n",
    "            \n",
    "        self.bias -= lr * bias_diff\n",
    "        self.kernel -= lr * kernel_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt2 = conv_layer(3, 4, 3, 3)\n",
    "in1 = np.ones([10,3,30,30])\n",
    "in1[:,1,:,:] = 2\n",
    "in1[:,2,:,:] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = filt2.forward(in1)\n",
    "out_diff_tensor = np.ones([10,4,30,30])\n",
    "filt2.backward(out_diff_tensor, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ -8409.  -8699.  -8409.]\n",
      "   [ -8699.  -8999.  -8699.]\n",
      "   [ -8409.  -8699.  -8409.]]\n",
      "\n",
      "  [[-16819. -17399. -16819.]\n",
      "   [-17399. -17999. -17399.]\n",
      "   [-16819. -17399. -16819.]]\n",
      "\n",
      "  [[-25229. -26099. -25229.]\n",
      "   [-26099. -26999. -26099.]\n",
      "   [-25229. -26099. -25229.]]]\n",
      "\n",
      "\n",
      " [[[ -8409.  -8699.  -8409.]\n",
      "   [ -8699.  -8999.  -8699.]\n",
      "   [ -8409.  -8699.  -8409.]]\n",
      "\n",
      "  [[-16819. -17399. -16819.]\n",
      "   [-17399. -17999. -17399.]\n",
      "   [-16819. -17399. -16819.]]\n",
      "\n",
      "  [[-25229. -26099. -25229.]\n",
      "   [-26099. -26999. -26099.]\n",
      "   [-25229. -26099. -25229.]]]\n",
      "\n",
      "\n",
      " [[[ -8409.  -8699.  -8409.]\n",
      "   [ -8699.  -8999.  -8699.]\n",
      "   [ -8409.  -8699.  -8409.]]\n",
      "\n",
      "  [[-16819. -17399. -16819.]\n",
      "   [-17399. -17999. -17399.]\n",
      "   [-16819. -17399. -16819.]]\n",
      "\n",
      "  [[-25229. -26099. -25229.]\n",
      "   [-26099. -26999. -26099.]\n",
      "   [-25229. -26099. -25229.]]]\n",
      "\n",
      "\n",
      " [[[ -8409.  -8699.  -8409.]\n",
      "   [ -8699.  -8999.  -8699.]\n",
      "   [ -8409.  -8699.  -8409.]]\n",
      "\n",
      "  [[-16819. -17399. -16819.]\n",
      "   [-17399. -17999. -17399.]\n",
      "   [-16819. -17399. -16819.]]\n",
      "\n",
      "  [[-25229. -26099. -25229.]\n",
      "   [-26099. -26999. -26099.]\n",
      "   [-25229. -26099. -25229.]]]]\n"
     ]
    }
   ],
   "source": [
    "print(filt2.kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]\n",
      " [-8999.]]\n"
     ]
    }
   ],
   "source": [
    "print(filt2.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9., 9., 9., 9.])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones([3,3,4])\n",
    "np.sum(a,axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class a(object):\n",
    "    def __init__(self):\n",
    "        None\n",
    "    \n",
    "    @staticmethod\n",
    "    def funca():\n",
    "        None\n",
    "        \n",
    "    def funcb(self):\n",
    "        a.funca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "a[2:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class max_pooling:\n",
    "    def __init__(self, stride):\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, in_tensor):\n",
    "        assert in_tensor.shape[2] % self.stride == 0\n",
    "        assert in_tensor.shape[3] % self.stride == 0\n",
    "        self.in_tensor = in_tensor\n",
    "\n",
    "        batch_num = in_tensor.shape[0]\n",
    "        in_channels = in_tensor.shape[1]\n",
    "        in_h = in_tensor.shape[2]\n",
    "        in_w = in_tensor.shape[3]\n",
    "        out_h = int(in_h/self.stride)\n",
    "        out_w = int(in_w/self.stride)\n",
    "        extend_in = in_tensor.reshape(batch_num, in_channels, out_h, self.stride, out_w, self.stride)\n",
    "        extend_in = extend_in.transpose(0,1,2,4,3,5).reshape(batch_num, in_channels, out_h, out_w, -1)\n",
    "\n",
    "        self.maxindex = np.argmax(extend_in, axis = 4)\n",
    "        out_tensor = extend_in.max(axis = 4)\n",
    "\n",
    "        return out_tensor\n",
    "\n",
    "    def backward(self, out_diff_tensor):\n",
    "        batch_num = out_diff_tensor.shape[0]\n",
    "        in_channels = out_diff_tensor.shape[1]\n",
    "        out_h = out_diff_tensor.shape[2]\n",
    "        out_w = out_diff_tensor.shape[3]\n",
    "        \n",
    "        \n",
    "        out_diff_tensor = out_diff_tensor.reshape(-1)\n",
    "        self.maxindex = self.maxindex.reshape(-1)\n",
    "        \n",
    "        in_diff_tensor = np.zeros([batch_num*in_channels*out_h*out_w, self.stride*self.stride])\n",
    "        in_diff_tensor[range(batch_num*in_channels*out_h*out_w), self.maxindex] = out_diff_tensor\n",
    "        in_diff_tensor = in_diff_tensor.reshape(batch_num, in_channels, out_h, out_w, self.stride, self.stride)\n",
    "        in_diff_tensor = in_diff_tensor.transpose(0,1,2,4,3,5)\n",
    "        in_diff_tensor = in_diff_tensor.reshape(batch_num, in_channels, out_h*self.stride, out_w*self.stride)\n",
    "        \n",
    "        self.in_diff_tensor = in_diff_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3,4],[4,3,2,1],[1,4,2,3],[2,3,4,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = max_pooling(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[4, 4],\n",
       "         [4, 4]]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool.forward(a.reshape(1,1,a.shape[0],a.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.  0.  0.  2.]\n",
      "   [ 1.  0.  0.  0.]\n",
      "   [ 0.  3.  0.  0.]\n",
      "   [ 0.  0.  1.  0.]]]]\n"
     ]
    }
   ],
   "source": [
    "diff = np.array([[1,2],[3,1]])\n",
    "pool.backward(diff.reshape(1,1,2,2))\n",
    "print(pool.in_diff_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
